"""
æ„é€ è‚¡ç¥¨æ—¥çº¿æ•°æ®é›†

å¤‡æ³¨ï¼š
    1. å¦‚ä½¿ç”¨ç”¨int(stock_code)ä»£è¡¨sidï¼Œå¿…é¡»åœ¨å†™å…¥èµ„äº§å…ƒæ•°æ®æ—¶ï¼Œæä¾›sidåˆ—
    2. é»˜è®¤åªå†™å…¥Aè‚¡ï¼Œä¸”åœ¨å¸‚çš„è‚¡ç¥¨æ•°æ®
    3. ä¿æŒä¸€è‡´æ€§ï¼Œåªéœ€è¦OHKCVåˆ—
    4. ç”±äºæ•°æ®æœŸé—´ä¸ä¸€è‡´ï¼Œå¦‚601607åˆ†çº¢æ´¾æ¯è‡ª2000å¹´å¼€å§‹ï¼Œè€Œæ—¥çº¿æ•°æ®è‡ª2010å¹´å¼€å§‹ï¼Œå¯¼è‡´æ— æ³•è®¡ç®—è°ƒæ•´ç³»æ•°ï¼Œ
       å±æ­£å¸¸ã€‚
    5. æˆäº¤é‡æ•°å€¼å¯èƒ½è¶…å‡ºint32ï¼Œå†™å…¥æ—¶é™¤100ï¼Œè¯»å–æ—¶ä¹˜ä»¥100ï¼Œéƒ¨åˆ†æŸå¤±ç²¾åº¦ã€‚
"""

import pandas as pd
import time
from cnswd.utils import make_logger, HotDataCache
from ..localdata import (fetch_single_equity, fetch_single_quity_adjustments,
                         fetch_single_minutely_equity, gen_asset_metadata)
from . import core as bundles
from .adjusts import ADJUST_FACTOR
from .refresh import CALENDAR_START

TODAY = pd.Timestamp('today').normalize()
log = make_logger('cnquandl', collection='zipline')


OHLCV_COLS = ['open', 'high', 'low', 'close', 'volume']


def _exchanges():
    # é€šè¿‡ `è‚¡ç¥¨.exchange = exchanges.exchange`æ¥å…³è”
    # æ·±è¯ä¿¡ è‚¡ç¥¨ä¿¡æ¯ ä¸Šå¸‚åœ°ç‚¹
    return pd.DataFrame({
        'exchange': ['æ·±äº¤æ‰€ä¸»æ¿', 'ä¸Šäº¤æ‰€', 'æ·±äº¤æ‰€ä¸­å°æ¿', 'æ·±äº¤æ‰€åˆ›ä¸šæ¿', 'ä¸Šäº¤æ‰€ç§‘åˆ›æ¿', 'æŒ‡æ•°'],
        'canonical_name': ['XSHE', 'XSHG', 'XSHE', 'XSHE', 'XSHG', 'XSHG'],
        'country_code': ['CN'] * 6
    })


def _to_sid(x):
    """ç¬¦å·è½¬æ¢ä¸ºsid"""
    return int(x)


def _update_splits(splits, asset_id, origin_data, start, end):
    if origin_data.empty:
        # å¦‚ä¸ºç©ºè¡¨ï¼Œç›´æ¥è¿”å›ï¼Œä¸è¿›è¡Œä»»ä½•å¤„ç†
        return
    ratio = origin_data['s_ratio'] + origin_data['z_ratio']
    # è°ƒæ•´é€‚åº”äºziplineç®—æ³•
    # date -> datetime64[ns]
    df = pd.DataFrame({
        'ratio': 1 / (1 + ratio),
        'effective_date': pd.to_datetime(origin_data.ex_date),
        'sid': asset_id
    })
    cond = (start <= df['effective_date']) & (df['effective_date'] <= end)
    # df['ratio'] = df.ratio.astype('float')
    splits.append(df.loc[cond, :])


def _update_dividends(dividends, asset_id, origin_data, start, end):
    if origin_data.empty:
        return
    # date -> datetime64[ns]
    df = pd.DataFrame({
        'record_date': pd.NaT,
        # pd.to_datetime(origin_data['record_date']),
        'ex_date':
        pd.to_datetime(origin_data['ex_date']),
        'declared_date': pd.NaT,
        # pd.to_datetime(origin_data['declared_date']),
        'pay_date': pd.NaT,
        # pd.to_datetime(origin_data['pay_date']),
        'amount':
        origin_data['amount'],
        'sid':
        asset_id
    })
    cond = (start <= df['pay_date']) & (df['pay_date'] <= end)
    dividends.append(df.loc[cond, :])


def gen_symbol_data(symbol_map, sessions, splits, dividends, is_minutely):
    if not is_minutely:
        cols = OHLCV_COLS + list(ADJUST_FACTOR.keys())
    else:
        cols = OHLCV_COLS
    start, end = sessions[0], sessions[-1]
    start, end = start.tz_localize(None), end.tz_localize(None)
    for _, symbol in symbol_map.iteritems():
        asset_id = _to_sid(symbol)
        if not is_minutely:
            raw_data = fetch_single_equity(
                symbol,
                start=sessions[0],
                end=sessions[-1],
            )
            # æ–°è‚¡å¯èƒ½å­˜åœ¨æ—¥çº¿å»¶è¿Ÿï¼Œä¼šè§¦å‘å¼‚å¸¸
            if not raw_data.empty:
                # ğŸ†— é™¤å»è°ƒæ•´
                # raw_data['volume'] = raw_data['volume'] / 100.0

                # ä»¥æ—¥æœŸã€ç¬¦å·ä¸ºç´¢å¼•
                raw_data.set_index(['date', 'symbol'], inplace=True)
                raw_data = raw_data.loc[:, cols]

                # æ—¶åŒºè°ƒæ•´ï¼Œä»¥0.0å¡«å……na
                # è½¬æ¢ä¸ºä»¥æ—¥æœŸä¸ºç´¢å¼•çš„è¡¨(ä¸sessionsä¿æŒä¸€è‡´)
                asset_data = raw_data.xs(symbol, level=1).reindex(
                    sessions.tz_localize(None)).fillna(0.0)
            else:
                asset_data = raw_data
        else:
            # å¤„ç†åˆ†é’Ÿçº§åˆ«æ•°æ®
            asset_data = fetch_single_minutely_equity(
                symbol,
                start=sessions[0],
                end=sessions[-1],
            ).tz_localize('Asia/Shanghai').tz_convert('utc')

        # é¡ºå¸¦å¤„ç†åˆ†çº¢æ´¾æ¯
        # è·å–åŸå§‹è°ƒæ•´æ•°æ®
        raw_adjustment = fetch_single_quity_adjustments(symbol,
                                                        start=sessions[0],
                                                        end=sessions[-1])
        # å½“éç©ºæ—¶æ‰æ‰§è¡Œ
        if not raw_adjustment.empty:
            # å‰”é™¤æœªæ¥äº‹ä»¶
            raw_adjustment = raw_adjustment[raw_adjustment.ex_date <= TODAY]
            # æ›´æ–°é€è½¬
            # é€è½¬æ¯”ç‡å¤§äº0æ‰æœ‰æ„ä¹‰
            ratio = raw_adjustment.s_ratio + raw_adjustment.z_ratio
            raw_splits = raw_adjustment.loc[ratio > 0.0, :]
            _update_splits(splits, asset_id, raw_splits, start, end)

            # æ›´æ–°è‚¡åˆ©
            raw_dividends = raw_adjustment.loc[raw_adjustment.amount > 0.0, :]
            _update_dividends(dividends, asset_id, raw_dividends, start, end)
        yield asset_id, asset_data


@bundles.register(
    'cndaily',
    calendar_name='XSHG',
    minutes_per_day=240)
def cndaily_bundle(environ, asset_db_writer, minute_bar_writer,
                   daily_bar_writer, adjustment_writer, calendar,
                   start_session, end_session, cache, show_progress,
                   output_dir):
    """Build a zipline data bundle from the cnstock dataset.
    """
    t = time.time()
    log.info('è¯»å–è‚¡ç¥¨å…ƒæ•°æ®......')
    # metadata = gen_asset_metadata(False)
    hc = HotDataCache(gen_asset_metadata, hour=9, minute=30, only_in=False)
    metadata = hc.data
    # èµ„äº§å…ƒæ•°æ®å†™æ³•è¦æ±‚æ·»åŠ `sid`åˆ—
    metadata['sid'] = metadata.symbol.map(_to_sid)
    symbol_map = metadata.symbol
    sessions = calendar.sessions_in_range(start_session, end_session)

    log.info('æ—¥çº¿æ•°æ®é›†ï¼ˆè‚¡ç¥¨æ•°é‡ï¼š{}ï¼‰'.format(len(symbol_map)))

    # å†™å…¥è‚¡ç¥¨å…ƒæ•°æ®
    if show_progress:
        log.info('å†™å…¥èµ„äº§å…ƒæ•°æ®')
    asset_db_writer.write(metadata, exchanges=_exchanges())

    splits = []
    dividends = []
    daily_bar_writer.write(
        gen_symbol_data(symbol_map,
                        sessions,
                        splits,
                        dividends,
                        is_minutely=False),
        show_progress=show_progress,
        has_additional_cols=True,
    )

    adjustment_writer.write(
        splits=None if len(splits) == 0 else pd.concat(splits,
                                                       ignore_index=True),
        dividends=None
        if len(dividends) == 0 else pd.concat(dividends, ignore_index=True),
    )
    log.info(f'å®Œæˆç”¨æ—¶ï¼š{time.time() - t:.2f}ç§’')


@bundles.register(
    'cnminutely',
    calendar_name='XSHG',
    start_session=CALENDAR_START,
    minutes_per_day=240)
def cnminutely_bundle(environ, asset_db_writer, minute_bar_writer,
                      daily_bar_writer, adjustment_writer, calendar,
                      start_session, end_session, cache, show_progress,
                      output_dir):
    """Build a zipline data bundle from the cnstock dataset.
    """
    t = time.time()
    log.info('è¯»å–è‚¡ç¥¨å…ƒæ•°æ®......')
    # åªä¿ç•™000002Aè‚¡æŒ‡æ•°ï¼Œä¸”æ—¥å†…è®¾å®šä¸ºå¸¸æ•°
    hc = HotDataCache(gen_asset_metadata, hour=9, minute=30, only_in=False)
    metadata = hc.data
    log.info("åˆ†é’Ÿçº§åˆ«æ•°æ®ï¼Œå›ºå®šä½¿ç”¨`000002ã€Aè‚¡æŒ‡æ•°ã€‘`æ—¥çº¿æ•°æ®ä½œä¸ºåŸºå‡†æ”¶ç›Šç‡")
    cond = metadata.symbol.str.len() == 6
    metadata = pd.concat(
        [metadata[metadata.symbol == '1000002'], metadata[cond]])
    # æµ‹è¯•åˆ‡ç‰‡
    # metadata = metadata.iloc[:20, :]

    metadata['sid'] = metadata.symbol.map(_to_sid)
    symbol_map = metadata.symbol

    sessions = calendar.sessions_in_range(start_session, end_session)

    log.info('åˆ†é’Ÿçº§åˆ«æ•°æ®é›†ï¼ˆè‚¡ç¥¨æ•°é‡ï¼š{}ï¼‰'.format(len(symbol_map)))

    # å†™å…¥è‚¡ç¥¨å…ƒæ•°æ®
    if show_progress:
        log.info('å†™å…¥èµ„äº§å…ƒæ•°æ®')
    asset_db_writer.write(metadata, exchanges=_exchanges())

    splits = []
    dividends = []
    minute_bar_writer.write(
        gen_symbol_data(symbol_map,
                        sessions,
                        splits,
                        dividends,
                        is_minutely=True),
        show_progress=show_progress,
    )

    adjustment_writer.write(
        splits=None if len(splits) == 0 else pd.concat(splits,
                                                       ignore_index=True),
        dividends=None
        if len(dividends) == 0 else pd.concat(dividends, ignore_index=True),
    )
    log.info(f'å®Œæˆç”¨æ—¶ï¼š{time.time() - t:.2f}ç§’')
